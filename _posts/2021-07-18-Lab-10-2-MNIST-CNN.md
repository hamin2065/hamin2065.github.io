---
layout: post
title:  MNIST CNN
subtitle:   
categories:  ai
tags: season-2
---
이 포스팅에서는 MNIST Data를 다운받아서 CNN으로 학습시키는 과정에 대해서 설명할 것이다.

# 학습단계
1. 라이브러리를 가져온다.(torch, torchvision등등)
2. GPU 사용 설정을 하고 random value를 위해서 seed를 설정해준다.
3. 학습에 사용되는 parameter를 설정해준다.(learning_rate, training_epochs, batch_size, etc)
4. 데이터셋을 가져오고 (학습에 쓰기 편하도록) loader를 만든다.
5. 학습 모델을 만든다.(Class CNN(torch.nn.Module))
6. Loss function (Criterion)을 선택하고 최적화 도구(Optimizer)를 선택한다.
7. 모델을 학습시키고 loss를 확인한다.(Criterion의 output)
8. 학습된 모델의 성능을 확인한다.

# 우리가 만들 CNN 구조 확인!
![MNIST_CNN](https://media.vlpt.us/images/gun1yun/post/69275de8-eb73-489e-8909-e72b73ce5c93/image.png)

(Layer 1) Convolution layer = (in_c = 1, out_c = 32, kernel_size = 3, stride = 1, padding = 1)
(Layer 1) MaxPool layer = (kernel_size = 2, stride = 2)

(Layer 2) Convolution layer = (in_c = 32, out_c = 64, kernel_size = 3, stride = 1, padding = 1)
(Layer 2) MaxPool layer = (kernel_size = 2, stride = 2)

    view => (batch_size x [7,7,64] => batch_size x [3136])
    Fully_Connect layer => (input = 3136, output = 10)

## 1. 라이브러리를 가져온다.(torch, torchvision등등)
```py
import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms

import torch.nn.init
```
- - -
## 2. GPU 사용 설정을 하고 random value를 위해서 seed를 설정해준다.
```py
device = 'cuda' if torch.cuda.is_available() else 'cpu'

torch.manual_seed(777)
if device == 'cuda':
    torch.cuda.manual_seed_all(777)
```
- - -
## 3. 학습에 사용되는 parameter를 설정해준다.(learning_rate, training_epochs, batch_size, etc)
```py
# parameters
learning_rate = 0.001
training_epochs = 15
batch_size = 100
```
밑에서 쓰일 parameter의 값들을 미리 지정해준다.


## 4. 데이터셋을 가져오고 (학습에 쓰기 편하도록) loader를 만든다.
```py
#MNIST dataset

mnist_Train = dsets.MNIST(root = 'MNIST_data/',
                         train = True,
                         transform = transforms.ToTensor(),
                         download=True)
mnist_test = dsets.MNIST(root = 'MNIST_data/',
                         train = True,
                         transform = transforms.ToTensor(),
                         download=True)
```
```py
data_loader = torch.utils.data.DataLoader(dataset = mnist_Train,
                                         batch_size = batch_size,
                                         shuffle = True,
                                         drop_last = True)
```

## 5. 학습 모델을 만든다.(Class CNN(torch.nn.Module))
```py
class CNN(nn.Module):
    
    def __init__(self):
        super(CNN, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(1,32,kernel_size = 3, stride = 1, padding = 1),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        
        self.layer2 = nn.Sequential(
            nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        
        self.fc = nn.Linear(7*7*64, 10, bias = True)
        torch.nn.init.xavier_uniform_(self.fc.weight)
        
    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        
        out = out.view(out.size(0), -1)
        return out
```
앞에서 설정한대로 Layer1과 Layer2를 init()함수에 만들어준다. 


## 6. Loss function (Criterion)을 선택하고 최적화 도구(Optimizer)를 선택한다.

```py
model = CNN().to(device)
```
```py
criterion = nn.CrossEntropyLoss().to(device)
optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)
```


## 7. 모델을 학습시키고 loss를 확인한다.(Criterion의 output)
```py
# training
total_batch = len(data_loader)

for epoch in range(training_epochs):
    avg_cost = 0
    
    for X, Y in data_loader: # X는 이미지, Y는 라벨
        X = X.to(device)
        Y = Y.to(device)
        
        optimizer.zero_grad()
        hypothesis = model(X)
        
        cost = criterion(hypothesis, Y) # 손실 계산
        cost.backward()
        optimizer.step() # optimizer를 통해서 나온값으로 모델 학습시키기
        
        
        avg_cost += cost / total_batch
    print('[Epoch:{}] cost = {}'.format(epoch+1, avg_cost))
    
print('Learning Finished')
```
출력결과

\[Epoch:1] cost = 0.22027970850467682<br>
\[Epoch:2] cost = 0.06089770793914795<br>
\[Epoch:3] cost = 0.04614785686135292<br>
\[Epoch:4] cost = 0.03658702224493027<br>
\[Epoch:5] cost = 0.03007662110030651<br>
\[Epoch:6] cost = 0.026113612577319145<br>
\[Epoch:7] cost = 0.020698705688118935<br>
\[Epoch:8] cost = 0.018392270430922508<br>
\[Epoch:9] cost = 0.015508195385336876<br>
\[Epoch:10] cost = 0.01339105237275362<br>
\[Epoch:11] cost = 0.011506284587085247<br>
\[Epoch:12] cost = 0.008892256766557693<br>
\[Epoch:13] cost = 0.00791729986667633<br>
\[Epoch:14] cost = 0.006305222399532795<br>
\[Epoch:15] cost = 0.007223725318908691<br>
Learning Finished
- - -
`optimizer.zero_grad()` : 역전파 단계 전에, optimizer 객체를 사용하여 (모델의 학습 가능한 가중치인) 갱신한다. <br>
변수들에 대한 모든 변화도(gradient)를 0으로 만드는 것이다.  이렇게 하는 이유는 기본적으로 `.backward()를` 호출할 때마다 변화도가 버퍼(buffer)에 (덮어쓰지 않고) 누적되기 때문이다.

`cost.backward()` : 역전파 단계 -> 모델의 매개변수들에 대한 손실의 변화도를 계산한다.

## 8. 학습된 모델의 성능을 확인한다.
```py
with torch.no_grad():
    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)
    Y_test = mnist_test.test_labels.to(device)
    
    prediction = model(X_test)
    correct_prediction = torch.argmax(prediction, 1) == Y_test
    accuracy = correct_prediction.float().mean()
    print('Accuracy:',accuracy.item())
```
출력결과 : Accuracy: 0.9928833246231079

*층을 더 쌓는다고 Loss가 줄어들고 Accuracy가 내려가는 것은 아니다. 효율적으로 층을 잘 쌓아야 하는 것이다.