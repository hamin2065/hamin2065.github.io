---
layout: post
title: Lab-09-03 Dropout
color: rgb(242,85,44)
tags: [AI, PyTorch]
---

# 학습목표
드롭아웃(Dropout) 에 대해 알아본다.
# 핵심키워드
- 과최적화(Overfitting)
- 드롭아웃(Dropout) 
- - -

# Overfitting
![coding](../../../assets/img/posts/Lab-09-3Dropout-3.jpg)
- `underfitting` : 모델이 너무 간단하기 때문에 학습 오류가 줄어들지 않는 것
- `overfitting` : 실제 분포보다 학습 샘플들 분포에 더 근접하게 학습되는 현상
![coding](../../../assets/img/posts/Lab-09-3Dropout-4.jpg)

![coding](../../../assets/img/posts/Lab-09-3Dropout-5.jpg)
 : overfitting이 일어나면 training dataset에는 아주 높은 정확성을 가지지만 test dataset에는 좋지 않은 정확도를 보인다.

# Solutions for overfitting
1. More training data : 더 많은 데이터로 학습을 시킨다.
2. Reduce the number of features : feature의 수를 줄인다.
3. Regularization : 정규화시키기
__4. Dropout__


# Dropout
![coding](../../../assets/img/posts/Lab-09-3Dropout-7.jpg)
: 각 레이어에서 쓰지 않을 노드(뉴런)들을 무작위로 선택해서 제외하고 학습시키는 것이다.

* 이때 주의할 점은 Train시에는 Dropout을 적용해야 하지만 Validation, Test에는 적용하면 안된다는 것이다.

# Code
![coding](../../../assets/img/posts/Lab-09-3Dropout-8.jpg)
![coding](../../../assets/img/posts/Lab-09-3Dropout-9.jpg)
